# my global config
global:
  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# A scrape configuration containing exactly one endpoint to scrape:
# Here it is Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'prometheus'

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
    - targets: ['localhost:9090']

  # Scrape Node Exporter every 15 seconds.
  - job_name: 'node-exporter'

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
    - targets: ['node-exporter:9100']


  - job_name: Confluent Cloud
    scrape_interval: 1m
    scrape_timeout: 1m
    honor_timestamps: true
    static_configs:
      - targets:
        - api.telemetry.confluent.cloud
    scheme: https
    basic_auth:
      username: K4RT6QD6TSEYIF4Z
      password: wUpXUSs8P5OMIYQxKClddmemcDLUZV09EmzqwBntsR/N5VfzkqX4Xhz3uRuteIN0
    metrics_path: /v2/metrics/cloud/export
    params:
      "resource.kafka.id":
        - lkc-mv1qx2
      # "resource.connector.id":
      # "resource.ksql.id":
      # "resource.schema_registry.id":
      # "metric":

